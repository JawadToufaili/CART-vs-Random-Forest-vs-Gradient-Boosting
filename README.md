Based on a dataset of 25,000 observations of adults, we are asked to build a decision tree model with categorical variables to predict an adults income. 
CART often leads to overfitting, that's why we often use Random forest, which brings in extra randomness to the model creating a wide diversity and better results , 
or Gradient Boosting which is similar to Random forest but instead observations are weighted rather than having same probability.
